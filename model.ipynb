{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   timestamp  numberBike  is_weekend  is_holiday  \\\n",
      "0  2023-08-29 10:15:38+00:00         8.0       False       False   \n",
      "1  2023-08-29 10:16:05+00:00         8.0       False       False   \n",
      "2  2023-08-29 10:17:04+00:00         8.0       False       False   \n",
      "3  2023-08-29 10:18:05+00:00         8.0       False       False   \n",
      "4  2023-08-29 10:19:05+00:00         8.0       False       False   \n",
      "\n",
      "   is_school_vacation  day_of_week  temp  max_temp  min_temp  precipitation  \\\n",
      "0                True            2  22.5      27.4      18.5            0.0   \n",
      "1                True            2  22.5      27.4      18.5            0.0   \n",
      "2                True            2  22.5      27.4      18.5            0.0   \n",
      "3                True            2  22.5      27.4      18.5            0.0   \n",
      "4                True            2  22.5      27.4      18.5            0.0   \n",
      "\n",
      "   wind_speed  visibility  fog  rain  snow  hail  thunder  tornado  \n",
      "0         7.9        11.9    0     0     0     0        0        0  \n",
      "1         7.9        11.9    0     0     0     0        0        0  \n",
      "2         7.9        11.9    0     0     0     0        0        0  \n",
      "3         7.9        11.9    0     0     0     0        0        0  \n",
      "4         7.9        11.9    0     0     0     0        0        0  \n",
      "Index(['timestamp', 'numberBike', 'is_weekend', 'is_holiday',\n",
      "       'is_school_vacation', 'day_of_week', 'temp', 'max_temp', 'min_temp',\n",
      "       'precipitation', 'wind_speed', 'visibility', 'fog', 'rain', 'snow',\n",
      "       'hail', 'thunder', 'tornado'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('data/enriched_bike_data.csv')\n",
    "print(df.head())\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme des données d'entrée: (40000, 18)\n",
      "Forme des données cibles: (40000,)\n",
      "Colonnes des données d'entrée: Index(['is_weekend', 'is_holiday', 'is_school_vacation', 'day_of_week', 'temp',\n",
      "       'max_temp', 'min_temp', 'precipitation', 'wind_speed', 'visibility',\n",
      "       'fog', 'rain', 'snow', 'hail', 'thunder', 'tornado', 'hour', 'minute'],\n",
      "      dtype='object')\n",
      "Types des colonnes: is_weekend            float64\n",
      "is_holiday            float64\n",
      "is_school_vacation    float64\n",
      "day_of_week           float64\n",
      "temp                  float64\n",
      "max_temp              float64\n",
      "min_temp              float64\n",
      "precipitation         float64\n",
      "wind_speed            float64\n",
      "visibility            float64\n",
      "fog                   float64\n",
      "rain                  float64\n",
      "snow                  float64\n",
      "hail                  float64\n",
      "thunder               float64\n",
      "tornado               float64\n",
      "hour                  float64\n",
      "minute                float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(['numberBike', 'timestamp'], axis=1)\n",
    "y = df['numberBike']\n",
    "date = df['timestamp']\n",
    "\n",
    "# Ajout de l'heure et des minutes\n",
    "X['hour'] = pd.to_datetime(date).dt.hour\n",
    "X['minute'] = pd.to_datetime(date).dt.minute\n",
    "X['hour'] = X['hour'].astype(int)\n",
    "X['minute'] = X['minute'].astype(int)\n",
    "\n",
    "\n",
    "X['day_of_week'] = X['day_of_week'].astype(int)\n",
    "\n",
    "boolean_columns = ['is_weekend', 'is_holiday', 'is_school_vacation', 'fog', 'rain', 'snow', 'hail', 'thunder', 'tornado']\n",
    "for col in boolean_columns:\n",
    "    X[col] = X[col].astype(int)\n",
    "\n",
    "X = X.astype(float)\n",
    "\n",
    "print(\"Forme des données d'entrée:\", X.shape)\n",
    "print(\"Forme des données cibles:\", y.shape)\n",
    "print(\"Colonnes des données d'entrée:\", X.columns)\n",
    "print(\"Types des colonnes:\", X.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme des tenseurs d'entraînement: torch.Size([32000, 18]) torch.Size([32000, 1])\n",
      "Forme des tenseurs de test: torch.Size([8000, 18]) torch.Size([8000, 1])\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train.values)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1)\n",
    "X_test_tensor = torch.FloatTensor(X_test.values)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values).reshape(-1, 1)\n",
    "\n",
    "print(\"Forme des tenseurs d'entraînement:\", X_train_tensor.shape, y_train_tensor.shape)\n",
    "print(\"Forme des tenseurs de test:\", X_test_tensor.shape, y_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avec normalisation des valeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# X = df.drop(['numberBike', 'timestamp'], axis=1)\n",
    "# y = df['numberBike']\n",
    "# date = df['timestamp']\n",
    "\n",
    "# # Ajout de l'heure et des minutes\n",
    "# X['hour'] = pd.to_datetime(date).dt.hour\n",
    "# X['minute'] = pd.to_datetime(date).dt.minute\n",
    "\n",
    "# # Assurez-vous que 'day_of_week' est traité comme un nombre\n",
    "# X['day_of_week'] = X['day_of_week'].astype(int)\n",
    "\n",
    "# # Normalisation de toutes les colonnes\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# print(\"Forme des données d'entrée:\", X_scaled.shape)\n",
    "# print(\"Forme des données cibles:\", y.shape)\n",
    "# print(\"Colonnes des données d'entrée:\", X_scaled.columns)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# X_train_tensor = torch.FloatTensor(X_train.values)\n",
    "# y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1)\n",
    "# X_test_tensor = torch.FloatTensor(X_test.values)\n",
    "# y_test_tensor = torch.FloatTensor(y_test.values).reshape(-1, 1)\n",
    "\n",
    "# print(\"Forme des tenseurs d'entraînement:\", X_train_tensor.shape, y_train_tensor.shape)\n",
    "# print(\"Forme des tenseurs de test:\", X_test_tensor.shape, y_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BikeNumberPredictor(\n",
      "  (layer1): Linear(in_features=18, out_features=64, bias=True)\n",
      "  (layer2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (layer3): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from BikeNumberPredictor import BikeNumberPredictor, AsymmetricMSELoss\n",
    "\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "model = BikeNumberPredictor(input_dim)\n",
    "print(model)\n",
    "\n",
    "criterion = AsymmetricMSELoss(beta=1.2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 0.3890\n",
      "Epoch [20/1000], Loss: 0.3233\n",
      "Epoch [30/1000], Loss: 0.3316\n",
      "Epoch [40/1000], Loss: 0.3031\n",
      "Epoch [50/1000], Loss: 0.3010\n",
      "Epoch [60/1000], Loss: 0.2946\n",
      "Epoch [70/1000], Loss: 0.2699\n",
      "Epoch [80/1000], Loss: 0.2905\n",
      "Epoch [90/1000], Loss: 0.2737\n",
      "Epoch [100/1000], Loss: 0.2838\n",
      "Epoch [110/1000], Loss: 0.2637\n",
      "Epoch [120/1000], Loss: 0.2544\n",
      "Epoch [130/1000], Loss: 0.2769\n",
      "Epoch [140/1000], Loss: 0.2568\n",
      "Epoch [150/1000], Loss: 0.2625\n",
      "Epoch [160/1000], Loss: 0.2657\n",
      "Epoch [170/1000], Loss: 0.2782\n",
      "Epoch [180/1000], Loss: 0.2370\n",
      "Epoch [190/1000], Loss: 0.2426\n",
      "Epoch [200/1000], Loss: 0.2591\n",
      "Epoch [210/1000], Loss: 0.2708\n",
      "Epoch [220/1000], Loss: 0.2420\n",
      "Epoch [230/1000], Loss: 0.2509\n",
      "Epoch [240/1000], Loss: 0.2766\n",
      "Epoch [250/1000], Loss: 0.2692\n",
      "Epoch [260/1000], Loss: 0.2467\n",
      "Epoch [270/1000], Loss: 0.2715\n",
      "Epoch [280/1000], Loss: 0.2588\n",
      "Epoch [290/1000], Loss: 0.3043\n",
      "Epoch [300/1000], Loss: 0.2801\n",
      "Epoch [310/1000], Loss: 0.2580\n",
      "Epoch [320/1000], Loss: 0.3231\n",
      "Epoch [330/1000], Loss: 0.2724\n",
      "Epoch [340/1000], Loss: 0.2867\n",
      "Epoch [350/1000], Loss: 0.2805\n",
      "Epoch [360/1000], Loss: 0.2714\n",
      "Epoch [370/1000], Loss: 0.2707\n",
      "Epoch [380/1000], Loss: 0.2638\n",
      "Epoch [390/1000], Loss: 0.2507\n",
      "Epoch [400/1000], Loss: 0.2543\n",
      "Epoch [410/1000], Loss: 0.2585\n",
      "Epoch [420/1000], Loss: 0.2729\n",
      "Epoch [430/1000], Loss: 0.2755\n",
      "Epoch [440/1000], Loss: 0.2690\n",
      "Epoch [450/1000], Loss: 0.2915\n",
      "Epoch [460/1000], Loss: 0.2624\n",
      "Epoch [470/1000], Loss: 0.2448\n",
      "Epoch [480/1000], Loss: 0.2415\n",
      "Epoch [490/1000], Loss: 0.2576\n",
      "Epoch [500/1000], Loss: 0.2539\n",
      "Epoch [510/1000], Loss: 0.2394\n",
      "Epoch [520/1000], Loss: 0.2472\n",
      "Epoch [530/1000], Loss: 0.2371\n",
      "Epoch [540/1000], Loss: 0.2424\n",
      "Epoch [550/1000], Loss: 0.2530\n",
      "Epoch [560/1000], Loss: 0.2392\n",
      "Epoch [570/1000], Loss: 0.2567\n",
      "Epoch [580/1000], Loss: 0.2459\n",
      "Epoch [590/1000], Loss: 0.2436\n",
      "Epoch [600/1000], Loss: 0.2513\n",
      "Epoch [610/1000], Loss: 0.2473\n",
      "Epoch [620/1000], Loss: 0.2573\n",
      "Epoch [630/1000], Loss: 0.2563\n",
      "Epoch [640/1000], Loss: 0.2306\n",
      "Epoch [650/1000], Loss: 0.2507\n",
      "Epoch [660/1000], Loss: 0.2514\n",
      "Epoch [670/1000], Loss: 0.2319\n",
      "Epoch [680/1000], Loss: 0.2383\n",
      "Epoch [690/1000], Loss: 0.2243\n",
      "Epoch [700/1000], Loss: 0.2257\n",
      "Epoch [710/1000], Loss: 0.2384\n",
      "Epoch [720/1000], Loss: 0.2436\n",
      "Epoch [730/1000], Loss: 0.2320\n",
      "Epoch [740/1000], Loss: 0.2496\n",
      "Epoch [750/1000], Loss: 0.2438\n",
      "Epoch [760/1000], Loss: 0.2514\n",
      "Epoch [770/1000], Loss: 0.2531\n",
      "Epoch [780/1000], Loss: 0.2506\n",
      "Epoch [790/1000], Loss: 0.2258\n",
      "Epoch [800/1000], Loss: 0.2337\n",
      "Epoch [810/1000], Loss: 0.2261\n",
      "Epoch [820/1000], Loss: 0.2180\n",
      "Epoch [830/1000], Loss: 0.2191\n",
      "Epoch [840/1000], Loss: 0.2361\n",
      "Epoch [850/1000], Loss: 0.2304\n",
      "Epoch [860/1000], Loss: 0.2142\n",
      "Epoch [870/1000], Loss: 0.2029\n",
      "Epoch [880/1000], Loss: 0.2170\n",
      "Epoch [890/1000], Loss: 0.2049\n",
      "Epoch [900/1000], Loss: 0.1980\n",
      "Epoch [910/1000], Loss: 0.1929\n",
      "Epoch [920/1000], Loss: 0.1941\n",
      "Epoch [930/1000], Loss: 0.1941\n",
      "Epoch [940/1000], Loss: 0.1908\n",
      "Epoch [950/1000], Loss: 0.1946\n",
      "Epoch [960/1000], Loss: 0.2060\n",
      "Epoch [970/1000], Loss: 0.1939\n",
      "Epoch [980/1000], Loss: 0.1929\n",
      "Epoch [990/1000], Loss: 0.2000\n",
      "Epoch [1000/1000], Loss: 0.2056\n",
      "Entraînement terminé!\n"
     ]
    }
   ],
   "source": [
    "y_train_adjusted = y_train * 0.8 # reduire la valeur de y_train pour eviter les erreurs de surestimation mieux vaut predire moins de velo que plus\n",
    "num_epochs = 1000\n",
    "batch_size = 64\n",
    "\n",
    "if(num_epochs==0):\n",
    "    model.load_state_dict(torch.load('model.pth'))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(X_train_tensor), batch_size):\n",
    "        batch_X = X_train_tensor[i:i+batch_size]\n",
    "        batch_y = y_train_tensor[i:i+batch_size]\n",
    "        \n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Entraînement terminé!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Évaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur quadratique moyenne sur l'ensemble de test: 0.2681\n",
      "\n",
      "Nombre d'échantillons testés: 8000\n",
      "Erreur absolue moyenne: 0.38\n",
      "Erreur maximale: 3.58\n",
      "  Valeur réelle: 8.00\n",
      "  Valeur prédite: 4.42\n",
      "Nombre d'erreurs supérieures à 1: 428\n",
      "Nombre d'erreurs inférieures ou égales à 1: 7572\n",
      "Pourcentage d'erreurs supérieures à 1: 5.35%\n",
      "\n",
      "Quelques exemples de prédictions:\n",
      "Valeur réelle: 5.00, Valeur prédite: 4.83, Erreur: 0.17\n",
      "Valeur réelle: 6.00, Valeur prédite: 5.75, Erreur: 0.25\n",
      "Valeur réelle: 6.00, Valeur prédite: 5.68, Erreur: 0.32\n",
      "Valeur réelle: 4.00, Valeur prédite: 3.94, Erreur: 0.06\n",
      "Valeur réelle: 6.00, Valeur prédite: 5.64, Erreur: 0.36\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor)\n",
    "    test_loss = criterion(y_pred, y_test_tensor)\n",
    "    print(f'Erreur quadratique moyenne sur l\\'ensemble de test: {test_loss.item():.4f}')\n",
    "\n",
    "num_samples = min(10000, len(X_test))\n",
    "\n",
    "indices = np.random.choice(len(X_test), num_samples, replace=False)\n",
    "\n",
    "errors = []\n",
    "max_error = 0\n",
    "max_error_actual = 0\n",
    "max_error_predicted = 0\n",
    "errors_greater_than_one = 0\n",
    "errors_less_than_one = 0\n",
    "\n",
    "for i in indices:\n",
    "    actual = y_test.iloc[i]\n",
    "    predicted = y_pred[i].item()\n",
    "    error = abs(actual - predicted)\n",
    "    errors.append(error)\n",
    "    \n",
    "    if error > max_error:\n",
    "        max_error = error\n",
    "        max_error_actual = actual\n",
    "        max_error_predicted = predicted\n",
    "    \n",
    "    if error > 1:\n",
    "        errors_greater_than_one += 1\n",
    "    else:\n",
    "        errors_less_than_one += 1\n",
    "\n",
    "mean_absolute_error = sum(errors) / len(errors)\n",
    "\n",
    "print(f\"\\nNombre d'échantillons testés: {num_samples}\")\n",
    "print(f\"Erreur absolue moyenne: {mean_absolute_error:.2f}\")\n",
    "print(f\"Erreur maximale: {max_error:.2f}\")\n",
    "print(f\"  Valeur réelle: {max_error_actual:.2f}\")\n",
    "print(f\"  Valeur prédite: {max_error_predicted:.2f}\")\n",
    "print(f\"Nombre d'erreurs supérieures à 1: {errors_greater_than_one}\")\n",
    "print(f\"Nombre d'erreurs inférieures ou égales à 1: {errors_less_than_one}\")\n",
    "print(f\"Pourcentage d'erreurs supérieures à 1: {(errors_greater_than_one / num_samples) * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nQuelques exemples de prédictions:\")\n",
    "num_examples = 5\n",
    "example_indices = np.random.choice(len(indices), num_examples, replace=False)\n",
    "for i in example_indices:\n",
    "    actual = y_test.iloc[indices[i]]\n",
    "    predicted = y_pred[indices[i]].item()\n",
    "    print(f'Valeur réelle: {actual:.2f}, Valeur prédite: {predicted:.2f}, Erreur: {abs(actual - predicted):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
